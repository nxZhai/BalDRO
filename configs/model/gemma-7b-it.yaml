model_args:
  pretrained_model_name_or_path: ???
  attn_implementation: 'flash_attention_2'
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: ???
template_args:
  apply_chat_template: True
  user_start_tag: "<bos><start_of_turn>user\n"
  user_end_tag: "<end_of_turn>\n"
  asst_start_tag: "<start_of_turn>model\n"
  asst_end_tag: "<end_of_turn>\n"
